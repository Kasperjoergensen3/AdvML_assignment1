Sun Feb 18 00:40:59 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |
| N/A   26C    P0              40W / 300W |      0MiB / 32768MiB |      0%   E. Process |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/zhome/4b/e/155339/miniconda3/envs/Denoising_EEG/bin/python3 AMLsrc/train_PartB.py --config "AMLsrc/configs/partB_DDPM.yaml" --version v1
Setting up configuration
T = 100
batch_size = 128
beta_1 = 0.0001
beta_T = 0.02
config = AMLsrc/configs/partB_DDPM.yaml
dim = 784
epochs = 100
lr = 0.001
model = DDPM
name = partB_ddpm_v1
network = Unet
seed = 42
transform_description = minus_one_to_one
version = v1
Using device: cuda
Using random seed: 42
Loading data
Size of train data: 60000
Size of test data: 10000
Setting up model with latent dimension: 784

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 20296624: <PartB> in cluster <dcc> Exited

Job <PartB> was submitted from host <gbarlogin1> by user <s204231> in cluster <dcc> at Sun Feb 18 00:40:57 2024
Job was executed on host(s) <4*n-62-20-12>, in queue <gpuv100>, as user <s204231> in cluster <dcc> at Sun Feb 18 00:40:58 2024
</zhome/4b/e/155339> was used as the home directory.
</zhome/4b/e/155339/Desktop/advML/AdvML_assignment1> was used as the working directory.
Started at Sun Feb 18 00:40:58 2024
Terminated at Sun Feb 18 00:41:10 2024
Results reported at Sun Feb 18 00:41:10 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
### General options
### â€“- specify queue --
#BSUB -q gpuv100
### -- set the job Name --
#BSUB -J PartB
### -- ask for number of cores (default: 1) --
#BSUB -n 4
### -- Select the resources: 1 gpu in exclusive process mode --
#BSUB -gpu "num=1:mode=exclusive_process"
### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now
#BSUB -W 24:00
# request 5GB of system-memory
#BSUB -R "rusage[mem=5GB]"
### -- set the email address --
# please uncomment the following line and put in your e-mail address,
# if you want to receive e-mail notifications on a non-default address
##BSUB -u your_email_address
### -- send notification at start --
##BSUB -B
### -- send notification at completion--
##BSUB -N
### -- Specify the output and error file. %J is the job-id --
### -- -o and -e mean append, -oo and -eo mean overwrite --
#BSUB -o HPC/outputs/PartB_%J.out
#BSUB -e HPC/outputs/PartB_%J.err
# -- end of LSF options --

nvidia-smi
# Load the cuda module
module load cuda/11.6

# Your Conda initialization step (path might be different based on your installation)
source /zhome/4b/e/155339/miniconda3/etc/profile.d/conda.sh
#activate conda environment
conda activate Denoising_EEG

# WANDB_API_KEY=${WANDB_API_KEY}
# # Log in to WandB
# wandb login $WANDB_API_KEY
#run the training script
#make train_gaussian_gpu

make run_partB

------------------------------------------------------------

Exited with exit code 2.

Resource usage summary:

    CPU time :                                   3.90 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     20480.00 MB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   93 sec.
    Turnaround time :                            13 sec.

The output (if any) is above this job summary.



PS:

Read file <HPC/outputs/PartB_20296624.err> for stderr output of this job.

